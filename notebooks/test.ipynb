{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading:\n",
      "  - Data directory: ../dataset\n",
      "  - Total images: 2000\n",
      "  - Classes: ['english', 'punjabi']\n",
      "Data Splitting:\n",
      "  - Training size: 1600\n",
      "  - Validation size: 400\n",
      "DataLoaders:\n",
      "  - Batch size: 32\n",
      "\n",
      "One batch preview:\n",
      "Batch shape: torch.Size([32, 3, 64, 64])\n",
      "Labels: tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1])\n",
      "2025-03-22 00:23:26.254 python[37423:23077919] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-03-22 00:23:26.254 python[37423:23077919] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
      "2025-03-22 00:23:52.250 python[37423:23077919] The class 'NSSavePanel' overrides the method identifier.  This method is implemented by class 'NSWindow'\n"
     ]
    }
   ],
   "source": [
    "!python /Users/sapandeepsinghsandhu/Desktop/Word_classifier/src/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Interactive Backend:\n",
    "The line matplotlib.use('TkAgg') forces matplotlib to use an interactive backend (you may change it to another backend if needed).\n",
    "\n",
    "Print Statements:\n",
    "\n",
    "The code prints out key details: data directory, total images, class names, training/validation split sizes, and batch size.\n",
    "When running as a main module, it prints one batch's shape and labels.\n",
    "Batch Visualization:\n",
    "The show_batch function prints the shape and labels of the batch and then displays a 3×3 grid of images using Matplotlib.\n",
    "\n",
    "Running the Module:\n",
    "When you run this module directly from the project root (ensuring the path to dataset is correct), it should print all the statistics and display the image grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure Explanation\n",
    "\n",
    "### Convolution Layer 1 (`Conv1`):\n",
    "\n",
    "- **Input**: RGB image with 3 channels\n",
    "- **Output**: Feature maps with 16 channels\n",
    "- **Operation**:\n",
    "\\[\n",
    "(3 \\text{ channels}) \\rightarrow \\text{Conv1} \\rightarrow (16 \\text{ channels})\n",
    "\\]\n",
    "\n",
    "### First Pooling Layer (`MaxPool`):\n",
    "\n",
    "- **Effect**: Reduces spatial dimensions by half\n",
    "- **Operation**:\n",
    "\\[\n",
    "64\\times64 \\rightarrow 32\\times32\n",
    "\\]\n",
    "\n",
    "### Convolution Layer 2 (`Conv2`):\n",
    "\n",
    "- **Input**: Feature maps from the first pooling layer\n",
    "- **Output**: Feature maps with 32 channels\n",
    "- **Operation**:\n",
    "\\[\n",
    "(16 \\text{ channels}) \\rightarrow \\text{Conv2} \\rightarrow (32 \\text{ channels})\n",
    "\\]\n",
    "\n",
    "### Second Pooling Layer (`MaxPool`):\n",
    "\n",
    "- **Effect**: Again reduces spatial dimensions by half\n",
    "- **Operation**:\n",
    "\\[\n",
    "32\\times32 \\rightarrow 16\\times16\n",
    "\\]\n",
    "\n",
    "### Fully Connected Layer (`fc1`):\n",
    "\n",
    "- **Flattens** the output from the second pooling layer.\n",
    "- Produces a vector of length equal to the number of classes (here, 2 classes).\n",
    "- **Flattened Feature Calculation**:\n",
    "\\[\n",
    "32 \\text{ (channels)} \\times 16 \\text{ (height)} \\times 16 \\text{ (width)} = 8192\n",
    "\\]\n",
    "\n",
    "Thus, the fully connected layer has:\n",
    "\\[\n",
    "8192 \\rightarrow 2 \\text{ classes}\n",
    "\\]\n",
    "\n",
    "## Testing the Model Architecture\n",
    "\n",
    "A simple test block verifies the model structure using a dummy input image (64×64 RGB):\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    model = YourModelClass()\n",
    "    dummy_input = torch.randn(1, 3, 64, 64)  # Batch size: 1, Channels: 3, Image size: 64×64\n",
    "    output = model(dummy_input)\n",
    "    print(\"Output shape:\", output.shape)  # Expected: [1, 2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "letter_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
